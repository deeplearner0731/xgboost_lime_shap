{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f81bdb-6a02-4632-b114-5be84f03d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import random\n",
    "import itertools\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38026344-400b-4f3e-868a-b9441fde7911",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num=random.sample(range(0,1000), 800)\n",
    "test_num=list(set(range(0,1000))-set(train_num))\n",
    "data_simulation = pd.read_csv('/ui/abv/liuzx18/project_shapley/simulation_data/simulation_0_6.csv').iloc[train_num,]\n",
    "data_simulation_test = pd.read_csv('/ui/abv/liuzx18/project_shapley/simulation_data/simulation_0_6.csv').iloc[test_num,]\n",
    "x_df=data_simulation[['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10']]\n",
    "X_=np.array(x_df)[:]\n",
    "x_df_test=data_simulation_test[['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10']]\n",
    "X_test=np.array(x_df_test)\n",
    "\n",
    "y_train=np.array(data_simulation[['y.binary']])\n",
    "y_train=y_train.reshape(800,)\n",
    "\n",
    "\n",
    "y_test=np.array(data_simulation_test[['y.binary']])\n",
    "y_test=y_test.reshape(200,)\n",
    "##training information:\n",
    "trt_=data_simulation[['treatment']]\n",
    "g_real=data_simulation[['sigpos']]\n",
    "##testing information:\n",
    "g_real_test=data_simulation_test[['sigpos']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_,trt_)\n",
    "pi_x = logreg.predict_proba(X_)\n",
    "pi_train=pi_x[:,1]\n",
    "\n",
    "\n",
    "\n",
    "X_train_trt=np.where(trt_==1,1,-1)\n",
    "X_train_trt=X_train_trt.reshape(800,)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "\n",
    "x_train_feature_pd=x_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99bda4c1-c258-40a1-baac-ea5ef734c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "EPS = 1e-12\n",
    "A   = X_train_trt          # ±1 array  (n, )\n",
    "X   = X_                   # feature matrix  (n, p)\n",
    "Y   = y_train              # binary {0,1} outcome  (n, )\n",
    "K   = 5                    # number of folds\n",
    "\n",
    "m1_train = np.zeros_like(Y, dtype=float)\n",
    "m0_train = np.zeros_like(Y, dtype=float)\n",
    "\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=123)\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # ---------- treated arm (+1) ----------\n",
    "    mask_t = (A[train_idx] == 1)\n",
    "    clf1 = xgb.XGBClassifier(\n",
    "        max_depth=3,\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='binary:logistic',   # default, but explicit is clearer\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    clf1.fit(X[train_idx][mask_t], Y[train_idx][mask_t])\n",
    "\n",
    "    # predict *probability* of class 1\n",
    "    m1_train[test_idx] = clf1.predict_proba(X[test_idx])[:, 1]\n",
    "\n",
    "    # ---------- control arm (−1) ----------\n",
    "    mask_c = (A[train_idx] == -1)\n",
    "    clf0 = xgb.XGBClassifier(\n",
    "        max_depth=3,\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    clf0.fit(X[train_idx][mask_c], Y[train_idx][mask_c])\n",
    "\n",
    "    m0_train[test_idx] = clf0.predict_proba(X[test_idx])[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71fe26e7-c6f8-42cb-9124-64642b86d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dr_pseudo_a_bin(y, A, pi, m1, m0):\n",
    "    A01   = (A + 1.0) / 2.0          # 0/1 coding\n",
    "    m_A   = np.where(A == 1, m1, m0)\n",
    "    denom = pi * (1.0 - pi) + EPS\n",
    "    return (A01 - pi) * (y - m_A) / denom + (m1 - m0)\n",
    "\n",
    "def dr_pseudo_w_bin(y, A, pi, m1, m0):\n",
    "    A01 = (A + 1.0) / 2.0\n",
    "    m_A = np.where(A == 1, m1, m0)\n",
    "    c   = (1.0 - A) / 2.0 + pi * A          # same weight as your code\n",
    "    phi = (A01 - pi) * (y - m_A) / (c + EPS) + (m1 - m0)\n",
    "    return phi, c + EPS                     # return both φ_DR and the weight\n",
    "\n",
    "\n",
    "def obj_dr_a_bin(predt, dtrain):\n",
    "    y  = dtrain.get_label()\n",
    "    φ  = dr_pseudo_a_bin(y, X_train_trt, pi_train, m1_train, m0_train)\n",
    "    grad = -2.0 * (φ - predt)\n",
    "    hess =  2.0 * np.ones_like(predt)\n",
    "    return grad, hess\n",
    "\n",
    "def eval_dr_a_bin(predt, dtrain):\n",
    "    y  = dtrain.get_label()\n",
    "    φ  = dr_pseudo_a_bin(y, X_train_trt, pi_train, m1_train, m0_train)\n",
    "    return 'DR_A_bin_loss', float(np.mean((φ - predt) ** 2))\n",
    "\n",
    "\n",
    "def obj_dr_w_bin(predt, dtrain):\n",
    "    y        = dtrain.get_label()\n",
    "    φ, c     = dr_pseudo_w_bin(y, X_train_trt, pi_train, m1_train, m0_train)\n",
    "    grad = -2.0 / c * (φ - predt)\n",
    "    hess =  2.0 / c\n",
    "    return grad, hess\n",
    "\n",
    "def eval_dr_w_bin(predt, dtrain):\n",
    "    y        = dtrain.get_label()\n",
    "    φ, c     = dr_pseudo_w_bin(y, X_train_trt, pi_train, m1_train, m0_train)\n",
    "    return 'DR_W_bin_loss', float(np.mean(((φ - predt) ** 2) / c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e39b4de-0720-484b-8086-09fec3be48af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train AUC: 0.9264253348291228\n",
      "Final Test AUC: 0.9311431143114312\n"
     ]
    }
   ],
   "source": [
    "best_params={'learning_rate':0.005,\n",
    "     'booster':'gbtree',\n",
    "     'max_depth':1,\n",
    "     'alpha':5,\n",
    "     'min_child_weight':5,\n",
    "     'tree_method':'exact',\n",
    "    'subsample':0.6,\n",
    "    'max_delta_step':1,\n",
    "    'gamma':1,\n",
    "    'max_bin':128\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "best_epoch=80\n",
    "\n",
    "\n",
    "\n",
    "model = xgb.train(\n",
    "best_params,\n",
    "dtrain,\n",
    "num_boost_round=best_epoch,  # Use the best num_boost_round\n",
    "obj=obj_dr_a_bin,\n",
    "feval=eval_dr_a_bin)\n",
    "\n",
    "# Predictions and Evaluation on Train Set\n",
    "pred_train = model.predict(dtrain)\n",
    "pred_train_prob = 1.0 / (1.0 + np.exp(-pred_train))  # Sigmoid transformation if needed\n",
    "auc_train = roc_auc_score(g_real.astype(int), pred_train_prob)\n",
    "print(f\"Final Train AUC: {auc_train}\")\n",
    "\n",
    "# Predictions and Evaluation on Test Set\n",
    "pred_test = model.predict(dtest)\n",
    "pred_test_prob = 1.0 / (1.0 + np.exp(-pred_test))  # Sigmoid transformation if needed\n",
    "auc_test = roc_auc_score(g_real_test.astype(int), pred_test_prob)\n",
    "print(f\"Final Test AUC: {auc_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de988fb9-2031-4c33-83a6-9899cb87eadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f5661-5a41-476e-b3b0-dba817453a40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-v2]",
   "language": "python",
   "name": "conda-env-.conda-v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
